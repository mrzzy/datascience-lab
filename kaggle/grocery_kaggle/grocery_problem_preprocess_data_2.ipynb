{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grocery Problem: Preprocessing Data 2\n",
    "In this notebook, we take steps to analyse and explore the grocery data and further prepare the data for later model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display # extract a feature record from each date\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We restore the preprocessed data from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.07 s, sys: 16 s, total: 23 s\n",
      "Wall time: 3.51 s\n",
      "CPU times: user 1.76 s, sys: 6 s, total: 7.76 s\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%time train_df = pd.read_feather(\"data/groceries/train_pp.feather\")\n",
    "%time test_df = pd.read_feather(\"data/groceries/test_pp.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing RAM consumption\n",
    "Currently the dataframes are very RAM heavy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Columns: 97 entries, index to unit_sales\n",
      "dtypes: float32(1), float64(95), int64(1)\n",
      "memory usage: 7.2 GB\n"
     ]
    }
   ],
   "source": [
    "train_df.info(max_cols=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3370464 entries, 0 to 3370463\n",
      "Columns: 96 entries, index to locale_Regional\n",
      "dtypes: float64(95), int64(1)\n",
      "memory usage: 2.4 GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info(max_cols=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data takes a large amount of ram, we reducefit my converting the  value from float64 to float32. This should half our RAM consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the floats in the df dataframe float64 to float32 inplace\n",
    "# returns the converted dataframe\n",
    "def downcast_float32(df):\n",
    "    for col_name in df.columns:\n",
    "        # find columns with float64 datatype\n",
    "        if df[col_name].dtype == 'float64':\n",
    "            # convert column to float32 inplace\n",
    "            df[col_name]= df[col_name].astype('float32', copy=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 5s, sys: 4min 18s, total: 8min 23s\n",
      "Wall time: 1min 35s\n",
      "CPU times: user 1min 26s, sys: 1min 25s, total: 2min 52s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%time train_df = downcast_float32(train_df)\n",
    "%time test_df = downcast_float32(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data fit confortablely into ram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Columns: 97 entries, index to unit_sales\n",
      "dtypes: float32(96), int64(1)\n",
      "memory usage: 3.7 GB\n"
     ]
    }
   ],
   "source": [
    "train_df.info(max_cols=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3370464 entries, 0 to 3370463\n",
      "Columns: 96 entries, index to locale_Regional\n",
      "dtypes: float32(95), int64(1)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info(max_cols=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "In this section, we explore the data using data exploratory techniques\n",
    "\n",
    "1. We first use `df.describe()` to obtain a statisical summary of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>cluster</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>...</th>\n",
       "      <th>type_y_Additional</th>\n",
       "      <th>type_y_Bridge</th>\n",
       "      <th>type_y_Event</th>\n",
       "      <th>type_y_Holiday</th>\n",
       "      <th>type_y_Transfer</th>\n",
       "      <th>type_y_Work Day</th>\n",
       "      <th>locale_Local</th>\n",
       "      <th>locale_National</th>\n",
       "      <th>locale_Regional</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.204970e+08</td>\n",
       "      <td>-4.783203e-07</td>\n",
       "      <td>-4.044922e-07</td>\n",
       "      <td>-4.315186e-09</td>\n",
       "      <td>-8.056640e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.325317e-10</td>\n",
       "      <td>-1.313324e-08</td>\n",
       "      <td>-5.569458e-09</td>\n",
       "      <td>-3.181518e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.267578e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.260474e-06</td>\n",
       "      <td>1.766699e-06</td>\n",
       "      <td>-2.043115e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.697266e-07</td>\n",
       "      <td>-1.236182e-06</td>\n",
       "      <td>8.707764e-07</td>\n",
       "      <td>8.104366e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.886751e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.466237e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.154970e+08</td>\n",
       "      <td>-1.747133e+00</td>\n",
       "      <td>-8.337458e-01</td>\n",
       "      <td>-1.670422e+00</td>\n",
       "      <td>-1.828894e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.078153e-01</td>\n",
       "      <td>-5.866986e-01</td>\n",
       "      <td>-1.689316e+00</td>\n",
       "      <td>-2.046201e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.916546e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.447308e-01</td>\n",
       "      <td>-8.532497e-01</td>\n",
       "      <td>-7.169128e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.713695e-01</td>\n",
       "      <td>-9.657815e-01</td>\n",
       "      <td>-3.063821e-01</td>\n",
       "      <td>-9.300000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.179970e+08</td>\n",
       "      <td>-8.658916e-01</td>\n",
       "      <td>-8.337458e-01</td>\n",
       "      <td>-9.349593e-01</td>\n",
       "      <td>-8.139869e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.610148e-01</td>\n",
       "      <td>-5.866986e-01</td>\n",
       "      <td>-8.128005e-01</td>\n",
       "      <td>-7.130504e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.916546e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.447308e-01</td>\n",
       "      <td>-8.532497e-01</td>\n",
       "      <td>-7.169128e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.713695e-01</td>\n",
       "      <td>-9.657815e-01</td>\n",
       "      <td>-3.063821e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.204970e+08</td>\n",
       "      <td>5.353633e-05</td>\n",
       "      <td>-8.337458e-01</td>\n",
       "      <td>4.565822e-02</td>\n",
       "      <td>6.927008e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.506993e-01</td>\n",
       "      <td>-5.866986e-01</td>\n",
       "      <td>6.371449e-02</td>\n",
       "      <td>6.850359e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.916546e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.447308e-01</td>\n",
       "      <td>-8.532497e-01</td>\n",
       "      <td>-7.169128e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.713695e-01</td>\n",
       "      <td>-9.657815e-01</td>\n",
       "      <td>-3.063821e-01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.229970e+08</td>\n",
       "      <td>8.659987e-01</td>\n",
       "      <td>1.198116e+00</td>\n",
       "      <td>9.649871e-01</td>\n",
       "      <td>6.946353e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.145852e-01</td>\n",
       "      <td>1.704453e+00</td>\n",
       "      <td>9.402295e-01</td>\n",
       "      <td>8.822864e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.916546e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.447308e-01</td>\n",
       "      <td>1.171990e+00</td>\n",
       "      <td>1.394870e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147619e+00</td>\n",
       "      <td>1.035431e+00</td>\n",
       "      <td>-3.063821e-01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>1.731944e+00</td>\n",
       "      <td>3.229978e+00</td>\n",
       "      <td>1.577873e+00</td>\n",
       "      <td>1.634225e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.856715e+00</td>\n",
       "      <td>1.704453e+00</td>\n",
       "      <td>1.816745e+00</td>\n",
       "      <td>1.793272e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.553270e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.900814e+00</td>\n",
       "      <td>1.171990e+00</td>\n",
       "      <td>1.394870e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147619e+00</td>\n",
       "      <td>1.035431e+00</td>\n",
       "      <td>3.263898e+00</td>\n",
       "      <td>1.537500e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              index            id          date     store_nbr      item_nbr  \\\n",
       "count  1.000000e+07  1.000000e+07  1.000000e+07  1.000000e+07  1.000000e+07   \n",
       "mean   1.204970e+08 -4.783203e-07 -4.044922e-07 -4.315186e-09 -8.056640e-10   \n",
       "std    2.886751e+06  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min    1.154970e+08 -1.747133e+00 -8.337458e-01 -1.670422e+00 -1.828894e+00   \n",
       "25%    1.179970e+08 -8.658916e-01 -8.337458e-01 -9.349593e-01 -8.139869e-01   \n",
       "50%    1.204970e+08  5.353633e-05 -8.337458e-01  4.565822e-02  6.927008e-02   \n",
       "75%    1.229970e+08  8.659987e-01  1.198116e+00  9.649871e-01  6.946353e-01   \n",
       "max    1.254970e+08  1.731944e+00  3.229978e+00  1.577873e+00  1.634225e+00   \n",
       "\n",
       "       onpromotion         class    perishable       cluster    dcoilwtico  \\\n",
       "count   10000000.0  1.000000e+07  1.000000e+07  1.000000e+07  1.000000e+07   \n",
       "mean           0.0 -5.325317e-10 -1.313324e-08 -5.569458e-09 -3.181518e-07   \n",
       "std            0.0  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min            0.0 -8.078153e-01 -5.866986e-01 -1.689316e+00 -2.046201e+00   \n",
       "25%            0.0 -7.610148e-01 -5.866986e-01 -8.128005e-01 -7.130504e-01   \n",
       "50%            0.0 -6.506993e-01 -5.866986e-01  6.371449e-02  6.850359e-03   \n",
       "75%            0.0  6.145852e-01  1.704453e+00  9.402295e-01  8.822864e-01   \n",
       "max            0.0  4.856715e+00  1.704453e+00  1.816745e+00  1.793272e+00   \n",
       "\n",
       "       ...  type_y_Additional  type_y_Bridge  type_y_Event  type_y_Holiday  \\\n",
       "count  ...       1.000000e+07     10000000.0  1.000000e+07    1.000000e+07   \n",
       "mean   ...       7.267578e-07            0.0  2.260474e-06    1.766699e-06   \n",
       "std    ...       1.000000e+00            0.0  1.000000e+00    1.000000e+00   \n",
       "min    ...      -3.916546e-01            0.0 -3.447308e-01   -8.532497e-01   \n",
       "25%    ...      -3.916546e-01            0.0 -3.447308e-01   -8.532497e-01   \n",
       "50%    ...      -3.916546e-01            0.0 -3.447308e-01   -8.532497e-01   \n",
       "75%    ...      -3.916546e-01            0.0 -3.447308e-01    1.171990e+00   \n",
       "max    ...       2.553270e+00            0.0  2.900814e+00    1.171990e+00   \n",
       "\n",
       "       type_y_Transfer  type_y_Work Day  locale_Local  locale_National  \\\n",
       "count     1.000000e+07       10000000.0  1.000000e+07     1.000000e+07   \n",
       "mean     -2.043115e-06              0.0 -9.697266e-07    -1.236182e-06   \n",
       "std       1.000000e+00              0.0  1.000000e+00     1.000000e+00   \n",
       "min      -7.169128e-01              0.0 -8.713695e-01    -9.657815e-01   \n",
       "25%      -7.169128e-01              0.0 -8.713695e-01    -9.657815e-01   \n",
       "50%      -7.169128e-01              0.0 -8.713695e-01    -9.657815e-01   \n",
       "75%       1.394870e+00              0.0  1.147619e+00     1.035431e+00   \n",
       "max       1.394870e+00              0.0  1.147619e+00     1.035431e+00   \n",
       "\n",
       "       locale_Regional    unit_sales  \n",
       "count     1.000000e+07  1.000000e+07  \n",
       "mean      8.707764e-07  8.104366e+00  \n",
       "std       1.000000e+00  2.466237e+01  \n",
       "min      -3.063821e-01 -9.300000e+02  \n",
       "25%      -3.063821e-01  2.000000e+00  \n",
       "50%      -3.063821e-01  4.000000e+00  \n",
       "75%      -3.063821e-01  8.000000e+00  \n",
       "max       3.263898e+00  1.537500e+04  \n",
       "\n",
       "[8 rows x 97 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We seperate the training data in training inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outs = train_df.unit_sales\n",
    "train_df.drop(columns=\"unit_sales\", inplace=True)\n",
    "train_ins = train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data contains only inputs so we just assign the test dataframe as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ins = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that are a large number of input features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 96 input features\n"
     ]
    }
   ],
   "source": [
    "n_features = train_ins.shape[-1]\n",
    "print(f\"there are {n_features} input features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "There are a large number of input features in this dataset, making visualisation and training a model to fit the data difficult\n",
    "\n",
    "\n",
    "### Dimentionality Reduction using PCA\n",
    "Hence we apply PCA to reduce no. of features in our inputs.\n",
    "\n",
    "> We have already done the feature scaling required before applying PCA in the previous notebook\n",
    "\n",
    "To measure how well a PCA decomposition captures the variance in the data/ how much infomation is lost in the dimention reduction process we create an error function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measures and returns the mean variance error\n",
    "def mean_variance_error(X, X_approx):\n",
    "    # Check no of features are valid (equal)\n",
    "    assert len(X) == len(X_approx)\n",
    "    n_features = len(X)\n",
    "    \n",
    "    # Average squared projection error  1/m * sum(|| X - X_approx ||2)\n",
    "    mean_sq_projection_error = np.sum(\n",
    "        np.linalg.norm(X - X_approx, ord=2)) / n_features\n",
    "    # total varation in data 1/m * sum(|| X - X_approx||2)\n",
    "    total_variation = np.sum(\n",
    "        np.linalg.norm(X, ord=2)) / n_features\n",
    "    \n",
    "    return mean_sq_projection_error / total_variation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try different no. of precipal components to try to decide how many principal components to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46b238c813b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_train_ins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheada\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ins' is not defined"
     ]
    }
   ],
   "source": [
    "sample_train_ins = train_ins.head(10000) # head because its time series\n",
    "\n",
    "n_components = np.random.randint(1, 96, size=80)\n",
    "errors = []\n",
    "\n",
    "for n_component in n_components:\n",
    "    pca = decomposition.PCA(n_components=n_component)\n",
    "    pca.fit(sample_train_ins)\n",
    "                    \n",
    "    train_pca_ins = pca.transform(sample_train_ins)\n",
    "    train_approx_ins = pca.inverse_transform(train_pca_ins)\n",
    "\n",
    "    errors.append(mean_variance_error(train_approx_ins, sample_train_ins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the trend of principal components to loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7febac2d5470>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "plt.xlabel(\"no. of components.\")\n",
    "plt.ylabel(\"mean variance error\")\n",
    "ax.xaxis.set_major_locator(plticker.MultipleLocator(base=4))\n",
    "plt.plot(n_components, errors, \"r*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis of this graph, we can see the optimal no. of components see to be around ~68 components.\n",
    "With this choice this no. of components, we try to compress the entire dataset.\n",
    "\n",
    "Instead of using normal PCA, we use incremental PCA to ensure that the procedure fits into ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 44s, sys: 2min 54s, total: 26min 38s\n",
      "Wall time: 5min 34s\n",
      "CPU times: user 50.7 s, sys: 38.5 s, total: 1min 29s\n",
      "Wall time: 45.6 s\n",
      "CPU times: user 7.73 s, sys: 6.07 s, total: 13.8 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "pca = decomposition.IncrementalPCA(n_components=68, batch_size=68 * 2)\n",
    "%time pca.fit(train_ins)\n",
    "%time train_ins = pca.transform(train_ins)\n",
    "%time test_ins = pca.transform(test_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 68 input features\n"
     ]
    }
   ],
   "source": [
    "n_features = train_ins.shape[-1]\n",
    "print(f\"there are {n_features} input features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting floats \n",
    "We further reduce the size of data by casting the dataset from `float64` to `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ins = train_ins.astype(\"float32\", copy=False)\n",
    "test_ins =  test_ins.astype(\"float32\", copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit data to disk\n",
    "The data is ready for building models.\n",
    "We commit them to disk using `numpy.savez()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training output to numpy array\n",
    "train_outs = train_outs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/groceries/groceries_dataset.npz\", \"wb\") as f:\n",
    "    np.savez(f, train_ins=train_ins, \n",
    "        train_outs=train_outs,\n",
    "        test_ins=test_ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the PCA object for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/groceries/pca.pickle\", \"wb\") as"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
